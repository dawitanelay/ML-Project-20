{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#importing libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "#keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.optimizers import SGD\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split \n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Input, Dropout\n",
    "from keras import Sequential\n",
    "from keras import regularizers\n",
    "from keras.layers import Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# for combining all the hyper-parameters\n",
    "import itertools \n",
    "from time import time\n",
    "from keras import initializers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading training and testing data from the csv file\n",
    "train_df = pd.read_csv ('../data/monks-2-test.csv',header=None).to_numpy()\n",
    "test_df = pd.read_csv ('../data/monks-2-train.csv',header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preparing train_df for training\n",
    "train_set = train_df[:, 1:7]\n",
    "train_label = train_df[:, 0]\n",
    "\n",
    "\n",
    "#Preparing test_df for testing\n",
    "test_set = test_df[:, 1:7]\n",
    "test_label = test_df[:, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((169, 6), (169,), (432, 6), (432,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " test_set.shape ,test_label.shape , train_set.shape , train_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot encoding \n",
    "from keras.utils import to_categorical\n",
    "\n",
    "def fix_zero(dataset):\n",
    "  return dataset - 1\n",
    "\n",
    "def to_one_hot_encoding(dataset):\n",
    "    fixed_dataset = fix_zero(dataset)\n",
    "    one_hot_dataset = []\n",
    "    for column in fixed_dataset.T:\n",
    "        one_hot_column = to_categorical(column)\n",
    "        for column_index in range(one_hot_column.shape[1]):\n",
    "            one_hot_dataset.append(one_hot_column[:,column_index])\n",
    "    return np.asarray(one_hot_dataset).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((432, 17), (432,), (169, 17), (169,))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_train = to_one_hot_encoding(train_set)\n",
    "one_hot_test  = to_one_hot_encoding(test_set)\n",
    "one_hot_train.shape , train_label.shape ,one_hot_test.shape , test_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(\n",
    "                    lr=0.7, \n",
    "                    num_hidden_units=4,\n",
    "                    activation_hidden=\"relu\", \n",
    "                    activation_out=\"softmax\",\n",
    "                    num_hidden_units2 = 3,\n",
    "                    activation_hidden2 = 'softmax',\n",
    "                    momentum=0.7, \n",
    "                    decay=0.01\n",
    "                ):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    initializer = initializers.GlorotNormal(seed=42) # has the parameter of seed to produce the same random sample.\n",
    "    model.add(Dense(units=num_hidden_units, kernel_initializer=initializer, input_dim=17, activation=activation_hidden))\n",
    "    model.add(Dense(units = num_hidden_units2,activation = activation_hidden2))\n",
    "    model.add(Dense(1, activation=activation_out)) \n",
    "\n",
    "    #optimizer\n",
    "    sgd = SGD(lr=lr, momentum=momentum, nesterov=False)  # We can add decay to hyper parameter list to get optimum value. \n",
    "\n",
    "    # Compile model\n",
    "    model.compile(optimizer=sgd, loss='mean_squared_error', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_1 = {}\n",
    "param_grid_1['lr'] = [0.1, 0.4, 0.7]\n",
    "param_grid_1['momentum'] = [0.1, 0.4, 0.7]\n",
    "param_grid_1['num_hidden_units'] = [2,3,4]\n",
    "param_grid_1['num_hidden_units2'] = [2,3,4]\n",
    "param_grid_1['activation_hidden'] = ['relu', 'sigmoid', 'softmax', 'tanh']\n",
    "param_grid_1['activation_hidden2'] = ['relu', 'sigmoid', 'softmax', 'tanh']\n",
    "param_grid_1['activation_out'] = ['softmax', 'tanh','sigmoid']\n",
    "param_grid_1['epochs'] = [120] \n",
    "param_grid_1['batch_size'] = [10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_out': 'tanh', 'batch_size': 30, 'epochs': 200, 'lr': 0.1, 'momentum': 0.4, 'num_hidden_units': 6}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_2 = {}\n",
    "param_grid_2['lr'] = [0.1,0.11,0.13,0.15]\n",
    "param_grid_2['momentum'] = [0.4,0.45, 0.5]\n",
    "param_grid_2['num_hidden_units'] = [3,4,5,6]\n",
    "param_grid_2['activation_hidden'] = ['relu']\n",
    "param_grid_2['activation_out'] = ['tanh']\n",
    "param_grid_2['epochs'] = [150, 200] \n",
    "param_grid_2['batch_size'] = [20, 30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_out': 'tanh', 'batch_size': 20, 'epochs': 150, 'lr': 0.11, 'momentum': 0.45, 'num_hidden_units': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_3 = {}\n",
    "param_grid_3['lr'] = [0.1,0.7]\n",
    "param_grid_3['momentum'] = [0.45, 0.48]\n",
    "param_grid_3['num_hidden_units'] = [2,3,4]\n",
    "param_grid_3['activation_hidden'] = ['relu']\n",
    "param_grid_3['activation_out'] = ['tanh']\n",
    "param_grid_3['epochs'] = [70,90,150] \n",
    "param_grid_3['batch_size'] = [10,20]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 0.995370 using {'activation_hidden': 'relu', 'activation_out': 'tanh', 'batch_size': 20, 'epochs': 90, 'lr': 0.1, 'momentum': 0.45, 'num_hidden_units': 3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_4 = {}\n",
    "param_grid_4['lr'] = [0.1,0.5]\n",
    "param_grid_4['momentum'] = [0.45, 0.6]\n",
    "param_grid_4['num_hidden_units'] = [3,4,5]\n",
    "param_grid_4['activation_hidden'] = ['relu']\n",
    "param_grid_4['activation_out'] = ['tanh']\n",
    "param_grid_4['epochs'] = [70,80,90] \n",
    "param_grid_4['batch_size'] = [10,20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_out': 'tanh', 'batch_size': 20, 'epochs': 80, 'lr': 0.1, 'momentum': 0.6, 'num_hidden_units': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_5 = {}\n",
    "param_grid_5['lr'] = [0.1, 0.4, 0.7]\n",
    "param_grid_5['momentum'] = [0.1, 0.4, 0.7]\n",
    "param_grid_5['num_hidden_units'] = [2, 6, 10]\n",
    "param_grid_5['num_hidden_units2'] = [2, 6, 10]\n",
    "param_grid_5['activation_hidden'] = ['relu', 'sigmoid', 'softmax', 'tanh']\n",
    "param_grid_5['activation_hidden2'] = ['relu', 'sigmoid', 'softmax', 'tanh']\n",
    "param_grid_5['activation_out'] = ['softmax', 'tanh']\n",
    "param_grid_5['epochs'] = [50, 100, 200] \n",
    "param_grid_5['batch_size'] = [10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "param_grid_6 = {}\n",
    "param_grid_6['lr'] = [0.1,0.01,0.001]\n",
    "param_grid_6['momentum'] = [0.1, 0.01,0.0001]\n",
    "param_grid_6['num_hidden_units'] = [4, 6, 7]\n",
    "param_grid_6['num_hidden_units2'] = [4, 6, 7,10]\n",
    "param_grid_6['activation_hidden'] = ['relu']\n",
    "param_grid_6['activation_hidden2'] = ['relu']\n",
    "param_grid_6['activation_out'] = ['softmax', 'tanh']\n",
    "param_grid_6['epochs'] = [50, 100] \n",
    "param_grid_6['batch_size'] = [10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_hidden2': 'relu', 'activation_out': 'tanh', 'batch_size': 10, 'epochs': 50, 'lr': 0.1, 'momentum': 0.1, 'num_hidden_units': 4, 'num_hidden_units2': 10}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "cv = RepeatedStratifiedKFold(n_splits=2, n_repeats=1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 2 folds for each of 3888 candidates, totalling 7776 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   55.1s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  4.3min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed: 10.2min\n",
      "[Parallel(n_jobs=-1)]: Done 784 tasks      | elapsed: 16.9min\n",
      "[Parallel(n_jobs=-1)]: Done 1234 tasks      | elapsed: 26.5min\n",
      "[Parallel(n_jobs=-1)]: Done 1784 tasks      | elapsed: 38.1min\n",
      "[Parallel(n_jobs=-1)]: Done 2434 tasks      | elapsed: 50.7min\n",
      "[Parallel(n_jobs=-1)]: Done 3184 tasks      | elapsed: 70.7min\n",
      "/home/anelay/anaconda3/lib/python3.7/site-packages/joblib/externals/loky/process_executor.py:706: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  \"timeout or by a memory leak.\", UserWarning\n",
      "[Parallel(n_jobs=-1)]: Done 4034 tasks      | elapsed: 84.9min\n",
      "[Parallel(n_jobs=-1)]: Done 4984 tasks      | elapsed: 99.9min\n",
      "[Parallel(n_jobs=-1)]: Done 6034 tasks      | elapsed: 116.1min\n",
      "[Parallel(n_jobs=-1)]: Done 7184 tasks      | elapsed: 133.5min\n",
      "[Parallel(n_jobs=-1)]: Done 7776 out of 7776 | elapsed: 142.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/120\n",
      "44/44 [==============================] - 0s 936us/step - loss: 0.2311 - accuracy: 0.6759\n",
      "Epoch 2/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2236 - accuracy: 0.6713\n",
      "Epoch 3/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2235 - accuracy: 0.6713\n",
      "Epoch 4/120\n",
      "44/44 [==============================] - 0s 966us/step - loss: 0.2232 - accuracy: 0.6713\n",
      "Epoch 5/120\n",
      "44/44 [==============================] - 0s 927us/step - loss: 0.2232 - accuracy: 0.6759\n",
      "Epoch 6/120\n",
      "44/44 [==============================] - 0s 963us/step - loss: 0.2235 - accuracy: 0.6713\n",
      "Epoch 7/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2224 - accuracy: 0.6667\n",
      "Epoch 8/120\n",
      "44/44 [==============================] - 0s 955us/step - loss: 0.2229 - accuracy: 0.6713\n",
      "Epoch 9/120\n",
      "44/44 [==============================] - 0s 804us/step - loss: 0.2217 - accuracy: 0.6713\n",
      "Epoch 10/120\n",
      "44/44 [==============================] - 0s 966us/step - loss: 0.2249 - accuracy: 0.6713\n",
      "Epoch 11/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2234 - accuracy: 0.6713\n",
      "Epoch 12/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2219 - accuracy: 0.6713\n",
      "Epoch 13/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2240 - accuracy: 0.6620\n",
      "Epoch 14/120\n",
      "44/44 [==============================] - 0s 985us/step - loss: 0.2231 - accuracy: 0.6713\n",
      "Epoch 15/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.6713\n",
      "Epoch 16/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2232 - accuracy: 0.6713\n",
      "Epoch 17/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2245 - accuracy: 0.6713\n",
      "Epoch 18/120\n",
      "44/44 [==============================] - 0s 937us/step - loss: 0.2216 - accuracy: 0.6713\n",
      "Epoch 19/120\n",
      "44/44 [==============================] - 0s 951us/step - loss: 0.2202 - accuracy: 0.6713\n",
      "Epoch 20/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.2218 - accuracy: 0.6713\n",
      "Epoch 21/120\n",
      "44/44 [==============================] - 0s 988us/step - loss: 0.2202 - accuracy: 0.6713\n",
      "Epoch 22/120\n",
      "44/44 [==============================] - 0s 982us/step - loss: 0.2207 - accuracy: 0.6713\n",
      "Epoch 23/120\n",
      "44/44 [==============================] - 0s 955us/step - loss: 0.2209 - accuracy: 0.6713\n",
      "Epoch 24/120\n",
      "44/44 [==============================] - 0s 919us/step - loss: 0.2192 - accuracy: 0.6713\n",
      "Epoch 25/120\n",
      "44/44 [==============================] - 0s 847us/step - loss: 0.2176 - accuracy: 0.6667\n",
      "Epoch 26/120\n",
      "44/44 [==============================] - 0s 827us/step - loss: 0.2126 - accuracy: 0.6690\n",
      "Epoch 27/120\n",
      "44/44 [==============================] - 0s 909us/step - loss: 0.2069 - accuracy: 0.6713\n",
      "Epoch 28/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1996 - accuracy: 0.6782\n",
      "Epoch 29/120\n",
      "44/44 [==============================] - 0s 940us/step - loss: 0.1907 - accuracy: 0.6736\n",
      "Epoch 30/120\n",
      "44/44 [==============================] - 0s 954us/step - loss: 0.1781 - accuracy: 0.6829\n",
      "Epoch 31/120\n",
      "44/44 [==============================] - 0s 861us/step - loss: 0.1702 - accuracy: 0.7106\n",
      "Epoch 32/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1625 - accuracy: 0.7731\n",
      "Epoch 33/120\n",
      "44/44 [==============================] - 0s 942us/step - loss: 0.1492 - accuracy: 0.8264\n",
      "Epoch 34/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.1297 - accuracy: 0.8819\n",
      "Epoch 35/120\n",
      "44/44 [==============================] - 0s 900us/step - loss: 0.1002 - accuracy: 0.9444\n",
      "Epoch 36/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0674 - accuracy: 0.9977\n",
      "Epoch 37/120\n",
      "44/44 [==============================] - 0s 945us/step - loss: 0.0363 - accuracy: 1.0000\n",
      "Epoch 38/120\n",
      "44/44 [==============================] - 0s 938us/step - loss: 0.0187 - accuracy: 1.0000\n",
      "Epoch 39/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0111 - accuracy: 1.0000\n",
      "Epoch 40/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0059 - accuracy: 1.0000\n",
      "Epoch 41/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0032 - accuracy: 1.0000\n",
      "Epoch 42/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 0.0027 - accuracy: 1.0000\n",
      "Epoch 43/120\n",
      "44/44 [==============================] - 0s 990us/step - loss: 0.0017 - accuracy: 1.0000\n",
      "Epoch 44/120\n",
      "44/44 [==============================] - 0s 917us/step - loss: 0.0014 - accuracy: 1.0000\n",
      "Epoch 45/120\n",
      "44/44 [==============================] - 0s 993us/step - loss: 0.0012 - accuracy: 1.0000\n",
      "Epoch 46/120\n",
      "44/44 [==============================] - 0s 895us/step - loss: 0.0010 - accuracy: 1.0000\n",
      "Epoch 47/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 8.9692e-04 - accuracy: 1.0000\n",
      "Epoch 48/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 7.7623e-04 - accuracy: 1.0000\n",
      "Epoch 49/120\n",
      "44/44 [==============================] - 0s 979us/step - loss: 7.0073e-04 - accuracy: 1.0000\n",
      "Epoch 50/120\n",
      "44/44 [==============================] - 0s 981us/step - loss: 6.0601e-04 - accuracy: 1.0000\n",
      "Epoch 51/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 5.4104e-04 - accuracy: 1.0000\n",
      "Epoch 52/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 5.0652e-04 - accuracy: 1.0000\n",
      "Epoch 53/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 4.8265e-04 - accuracy: 1.0000\n",
      "Epoch 54/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 4.8054e-04 - accuracy: 1.0000\n",
      "Epoch 55/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.9635e-04 - accuracy: 1.0000\n",
      "Epoch 56/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.7025e-04 - accuracy: 1.0000\n",
      "Epoch 57/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.4489e-04 - accuracy: 1.0000\n",
      "Epoch 58/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.2440e-04 - accuracy: 1.0000\n",
      "Epoch 59/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 3.0323e-04 - accuracy: 1.0000\n",
      "Epoch 60/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.9070e-04 - accuracy: 1.0000\n",
      "Epoch 61/120\n",
      "44/44 [==============================] - 0s 933us/step - loss: 2.7019e-04 - accuracy: 1.0000\n",
      "Epoch 62/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.5927e-04 - accuracy: 1.0000\n",
      "Epoch 63/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.4289e-04 - accuracy: 1.0000\n",
      "Epoch 64/120\n",
      "44/44 [==============================] - 0s 873us/step - loss: 2.3440e-04 - accuracy: 1.0000\n",
      "Epoch 65/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 2.2470e-04 - accuracy: 1.0000\n",
      "Epoch 66/120\n",
      "44/44 [==============================] - 0s 976us/step - loss: 2.1279e-04 - accuracy: 1.0000\n",
      "Epoch 67/120\n",
      "44/44 [==============================] - 0s 983us/step - loss: 2.0394e-04 - accuracy: 1.0000\n",
      "Epoch 68/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.9822e-04 - accuracy: 1.0000\n",
      "Epoch 69/120\n",
      "44/44 [==============================] - 0s 999us/step - loss: 1.8866e-04 - accuracy: 1.0000\n",
      "Epoch 70/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.8103e-04 - accuracy: 1.0000\n",
      "Epoch 71/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.7616e-04 - accuracy: 1.0000\n",
      "Epoch 72/120\n",
      "44/44 [==============================] - 0s 981us/step - loss: 1.7005e-04 - accuracy: 1.0000\n",
      "Epoch 73/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.6423e-04 - accuracy: 1.0000\n",
      "Epoch 74/120\n",
      "44/44 [==============================] - 0s 952us/step - loss: 1.5864e-04 - accuracy: 1.0000\n",
      "Epoch 75/120\n",
      "44/44 [==============================] - 0s 964us/step - loss: 1.5249e-04 - accuracy: 1.0000\n",
      "Epoch 76/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.4948e-04 - accuracy: 1.0000\n",
      "Epoch 77/120\n",
      "44/44 [==============================] - 0s 989us/step - loss: 1.4494e-04 - accuracy: 1.0000\n",
      "Epoch 78/120\n",
      "44/44 [==============================] - 0s 951us/step - loss: 1.4009e-04 - accuracy: 1.0000\n",
      "Epoch 79/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.3488e-04 - accuracy: 1.0000\n",
      "Epoch 80/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "44/44 [==============================] - 0s 1ms/step - loss: 1.3326e-04 - accuracy: 1.0000\n",
      "Epoch 81/120\n",
      "44/44 [==============================] - 0s 956us/step - loss: 1.3730e-04 - accuracy: 1.0000\n",
      "Epoch 82/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.2441e-04 - accuracy: 1.0000\n",
      "Epoch 83/120\n",
      "44/44 [==============================] - 0s 928us/step - loss: 1.2991e-04 - accuracy: 1.0000\n",
      "Epoch 84/120\n",
      "44/44 [==============================] - 0s 986us/step - loss: 1.1824e-04 - accuracy: 1.0000\n",
      "Epoch 85/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 1.1424e-04 - accuracy: 1.0000\n",
      "Epoch 86/120\n",
      "44/44 [==============================] - 0s 960us/step - loss: 1.1144e-04 - accuracy: 1.0000\n",
      "Epoch 87/120\n",
      "44/44 [==============================] - 0s 961us/step - loss: 1.0874e-04 - accuracy: 1.0000\n",
      "Epoch 88/120\n",
      "44/44 [==============================] - 0s 984us/step - loss: 1.0746e-04 - accuracy: 1.0000\n",
      "Epoch 89/120\n",
      "44/44 [==============================] - 0s 869us/step - loss: 1.0325e-04 - accuracy: 1.0000\n",
      "Epoch 90/120\n",
      "44/44 [==============================] - 0s 965us/step - loss: 1.0105e-04 - accuracy: 1.0000\n",
      "Epoch 91/120\n",
      "44/44 [==============================] - 0s 955us/step - loss: 1.0083e-04 - accuracy: 1.0000\n",
      "Epoch 92/120\n",
      "44/44 [==============================] - 0s 944us/step - loss: 9.7345e-05 - accuracy: 1.0000\n",
      "Epoch 93/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 9.4256e-05 - accuracy: 1.0000\n",
      "Epoch 94/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 9.5938e-05 - accuracy: 1.0000\n",
      "Epoch 95/120\n",
      "44/44 [==============================] - 0s 998us/step - loss: 9.1469e-05 - accuracy: 1.0000\n",
      "Epoch 96/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 8.8674e-05 - accuracy: 1.0000\n",
      "Epoch 97/120\n",
      "44/44 [==============================] - 0s 978us/step - loss: 8.6888e-05 - accuracy: 1.0000\n",
      "Epoch 98/120\n",
      "44/44 [==============================] - 0s 918us/step - loss: 8.4592e-05 - accuracy: 1.0000\n",
      "Epoch 99/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 8.4138e-05 - accuracy: 1.0000\n",
      "Epoch 100/120\n",
      "44/44 [==============================] - 0s 961us/step - loss: 8.1960e-05 - accuracy: 1.0000\n",
      "Epoch 101/120\n",
      "44/44 [==============================] - 0s 925us/step - loss: 7.9986e-05 - accuracy: 1.0000\n",
      "Epoch 102/120\n",
      "44/44 [==============================] - 0s 917us/step - loss: 7.8499e-05 - accuracy: 1.0000\n",
      "Epoch 103/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 7.7515e-05 - accuracy: 1.0000\n",
      "Epoch 104/120\n",
      "44/44 [==============================] - 0s 934us/step - loss: 7.6212e-05 - accuracy: 1.0000\n",
      "Epoch 105/120\n",
      "44/44 [==============================] - 0s 914us/step - loss: 7.4628e-05 - accuracy: 1.0000\n",
      "Epoch 106/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 7.4192e-05 - accuracy: 1.0000\n",
      "Epoch 107/120\n",
      "44/44 [==============================] - 0s 946us/step - loss: 7.3214e-05 - accuracy: 1.0000\n",
      "Epoch 108/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 7.1935e-05 - accuracy: 1.0000\n",
      "Epoch 109/120\n",
      "44/44 [==============================] - 0s 980us/step - loss: 6.9717e-05 - accuracy: 1.0000\n",
      "Epoch 110/120\n",
      "44/44 [==============================] - 0s 962us/step - loss: 6.8767e-05 - accuracy: 1.0000\n",
      "Epoch 111/120\n",
      "44/44 [==============================] - 0s 994us/step - loss: 6.7050e-05 - accuracy: 1.0000\n",
      "Epoch 112/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.8839e-05 - accuracy: 1.0000\n",
      "Epoch 113/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.5195e-05 - accuracy: 1.0000\n",
      "Epoch 114/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.4359e-05 - accuracy: 1.0000\n",
      "Epoch 115/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.2949e-05 - accuracy: 1.0000\n",
      "Epoch 116/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.1962e-05 - accuracy: 1.0000\n",
      "Epoch 117/120\n",
      "44/44 [==============================] - 0s 1ms/step - loss: 6.0993e-05 - accuracy: 1.0000\n",
      "Epoch 118/120\n",
      "44/44 [==============================] - 0s 990us/step - loss: 6.0621e-05 - accuracy: 1.0000\n",
      "Epoch 119/120\n",
      "44/44 [==============================] - 0s 961us/step - loss: 5.9333e-05 - accuracy: 1.0000\n",
      "Epoch 120/120\n",
      "44/44 [==============================] - 0s 985us/step - loss: 5.9467e-05 - accuracy: 1.0000\n",
      "Total Running Time: %f 8546.459070205688\n",
      "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_hidden2': 'relu', 'activation_out': 'tanh', 'batch_size': 10, 'epochs': 120, 'lr': 0.1, 'momentum': 0.1, 'num_hidden_units': 3, 'num_hidden_units2': 3}\n"
     ]
    }
   ],
   "source": [
    "start=time()\n",
    "model = KerasClassifier(build_fn=create_model) \n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid_1,n_jobs=-1,cv=cv,verbose=1) \n",
    "grid_result = grid.fit(one_hot_train, train_label)\n",
    "end=time() \n",
    "print(\"Total Running Time: %f\",end-start)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_)) \n",
    "# summarize results\n",
    "# print(\"Mean\\tSTD\\tParams\")\n",
    "# means = grid_result.cvresults['mean_test_score']\n",
    "# stds = grid_result.cvresults['std_test_score']\n",
    "# params = grid_result.cvresults['params']\n",
    "# for mean, stdev, param in zip(means, stds, params):\n",
    "#     print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_hidden2': 'relu', 'activation_out': 'tanh', 'batch_size': 10, 'epochs': 50, 'lr': 0.1, 'momentum': 0.1, 'num_hidden_units': 10, 'num_hidden_units2': 10}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Total Running Time: %f 261.22601437568665\n",
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_hidden2': 'relu', 'activation_out': 'tanh', 'batch_size': 10, 'epochs': 50, 'lr': 0.1, 'momentum': 0.1, 'num_hidden_units': 4, 'num_hidden_units2': 7}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Best: 1.000000 using {'activation_hidden': 'relu', 'activation_hidden2': 'relu', 'activation_out': 'tanh', 'batch_size': 10, 'epochs': 120, 'lr': 0.1, 'momentum': 0.1, 'num_hidden_units': 4}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
